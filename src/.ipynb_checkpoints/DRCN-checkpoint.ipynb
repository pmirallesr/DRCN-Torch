{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "train = \"SVHN\"\n",
    "test = \"MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d894c70251c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 ([torchvision.transforms.ToTensor(), \\\n\u001b[0;32m---> 24\u001b[0;31m                   \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 ])), batch_size = train_batch_size, shuffle = True)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'train'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "train_MNIST_loader = torch.utils.data.DataLoader \\\n",
    "                (torchvision.datasets.MNIST('/home/pmirallesr/eclipse-workspace/DRCN/data/', \\\n",
    "                train = True, download = True, \\\n",
    "                transform = torchvision.transforms.Compose\\\n",
    "                ([torchvision.transforms.ToTensor(), \\\n",
    "                  torchvision.transforms.Normalize((0.1307,), (0.3081))\\\n",
    "                ])), batch_size = train_batch_size, shuffle = True)\n",
    "\n",
    "test_MNIST_loader = torch.utils.data.DataLoader \\\n",
    "                (torchvision.datasets.MNIST('/home/pmirallesr/eclipse-workspace/DRCN/data/', \\\n",
    "                train = True, download = True, \\\n",
    "                transform = torchvision.transforms.Compose\\\n",
    "                ([torchvision.transforms.ToTensor(), \\\n",
    "                  torchvision.transforms.Normalize((0.1307,), (0.3081))\\\n",
    "                ])), batch_size = test_batch_size, shuffle = True)\n",
    "\n",
    "train_SVHN_loader = torch.utils.data.DataLoader \\\n",
    "                (torchvision.datasets.SVHN('/home/pmirallesr/eclipse-workspace/DRCN/data/', \\\n",
    "                train = True, download = True, \\\n",
    "                transform = torchvision.transforms.Compose\\\n",
    "                ([torchvision.transforms.ToTensor(), \\\n",
    "                  torchvision.transforms.Normalize((0.1307,), (0.3081))\\\n",
    "                ])), batch_size = train_batch_size, shuffle = True)\n",
    "\n",
    "test_SVHN_loader = torch.utils.data.DataLoader \\\n",
    "                (torchvision.datasets.SVHN('/home/pmirallesr/eclipse-workspace/DRCN/data/', \\\n",
    "                train = True, download = True, \\\n",
    "                transform = torchvision.transforms.Compose\\\n",
    "                ([torchvision.transforms.ToTensor(), \\\n",
    "                  torchvision.transforms.Normalize((0.1307,), (0.3081))\\\n",
    "                ])), batch_size = test_batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "for batch_idx, (example_data, example_targets) in examples:\n",
    "    print(batch_idx)\n",
    "    print(example_data.shape)\n",
    "    print(example_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f313c6378b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Device configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "# Move function to some utils module\n",
    "def calcPoolOutputSize(inputSize, kernelSize):\n",
    "    return inputSize/(kernelSize[0]*kernelSize[1])\n",
    "\n",
    "       \n",
    "class Encoder(nn.module):\n",
    "    \"\"\"Encoder common to Autoencoder and labeller\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize DomainRegressor.\"\"\"\n",
    "        super(DomainRegressor, self).__init__()\n",
    "        \n",
    "        #Size Parameters\n",
    "        \n",
    "        conv1OutputSize = 100\n",
    "        conv1KernelSize = 5\n",
    "        \n",
    "        maxPool1Size = (2,2)\n",
    "        \n",
    "        conv2OutputSize = 150\n",
    "        conv2KernelSize = 5\n",
    "        \n",
    "        maxPool2Size = (2,2)\n",
    "        \n",
    "        conv3OutputSize = 200\n",
    "        conv3KernelSize = 3\n",
    "        \n",
    "        # Placeholder ranges\n",
    "        fc4OutputSize = range(300,1000,50)\n",
    "        fc5OutputSize = range(300,1000,50)\n",
    "        \n",
    "        \n",
    "        # Size Calculations\n",
    "        conv1InputSize = IMGSIZE\n",
    "        \n",
    "        conv2InputSize = calcPoolOutputSize(conv1OutputSize,maxPool1Size)\n",
    "        \n",
    "        conv3InputSize = calcPoolOutputSize(conv2OutputSize,maxPool2Size)\n",
    "        \n",
    "        fc4InputSize = conv3OutputSize\n",
    "        \n",
    "        fc5InputSize = fc4OutputSize\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(conv1InputSize, conv1OutputSize, conv1KernelSize)\n",
    "        self.maxPool2D1 = nn.MaxPool2D(maxPool1Size)\n",
    "        self.conv2 = nn.Conv2d(conv2InputSize, conv2OutputSize, conv2KernelSize)\n",
    "        self.maxPool2D2 = nn.MaxPool2D(maxPool2Size)\n",
    "        self.conv3 = nn.Conv2d(conv3InputSize, conv3OutputSize, conv3KernelSize)\n",
    "        \n",
    "        self.fc4 = nn.Linear(fc4InputSize, fc4OutputSize)\n",
    "        self.fc5 = nn.Linear(fc5InputSize, fc5OutputSize)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass X and return probabilities of source and domain.\"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.maxPool2D1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.maxPool2D2(x))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.maxPool2D3(x))\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fcOUT(x))\n",
    "        return x\n",
    "\n",
    "class Labeller(Encoder):\n",
    "    \"\"\" The labeller part of the network is constituted by \n",
    "    the common Encoder plus a labelling fully connected layer\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        fc3OutputSize = numLabels\n",
    "        fc3InputSize = self.fc5.out_features\n",
    "        self.fcOUT = nn.Linear(fc3InputSize, fc3OutputSize)    \n",
    "\n",
    "class Autoencoder(Encoder):\n",
    "    \"\"\"The autoencoder is constituted by the Encoder common to\n",
    "    the labeller and itself, and a decoder part that is a mirror\n",
    "    image of the Encoder\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize DomainRegressor.\"\"\"\n",
    "        super(DomainRegressor, self).__init__()\n",
    "        \n",
    "        #Size Parameters\n",
    "        \n",
    "        deconv1InputSize = 100\n",
    "        deconv1KernelSize = 5\n",
    "        \n",
    "        maxUnspool1Size = (2,2)\n",
    "        \n",
    "        deconv2InputSize = 150\n",
    "        deconv2KernelSize = 5\n",
    "        \n",
    "        maxUnspool2Size = (2,2)\n",
    "        \n",
    "        deconv3InputSize = 200\n",
    "        deconv3KernelSize = 3\n",
    "        \n",
    "        # Placeholder ranges\n",
    "        fc7OutputSize = range(300,1000,50)\n",
    "        fc6OutputSize = range(300,1000,50)\n",
    "        \n",
    "        \n",
    "        # Size Calculations\n",
    "        deconv1OutputSize = IMGSIZE\n",
    "        \n",
    "        deconv2OutputSize = calcPoolOutputSize(conv1OutputSize,maxPool1Size)\n",
    "        \n",
    "        deconv3OutputSize = calcPoolOutputSize(conv2OutputSize,maxPool2Size)\n",
    "        \n",
    "        fc7OutputSize = conv3OutputSize\n",
    "        \n",
    "        fc6OutputSize = fc1OutputSize\n",
    "        \n",
    "        self.deconv1 = nn.Conv2d(conv1InputSize, conv1OutputSize, conv1KernelSize)\n",
    "        self.maxUnspool2D1 = nn.MaxPool2D(maxPool1Size)\n",
    "        self.deconv2 = nn.Conv2d(conv2InputSize, conv2OutputSize, conv2KernelSize)\n",
    "        self.maxUnspool2D2 = nn.MaxPool2D(maxPool2Size)\n",
    "        self.deconv3 = nn.Conv2d(conv3InputSize, conv3OutputSize, conv3KernelSize)\n",
    "        \n",
    "        self.fc7 = nn.Linear(fc7InputSize, fc7OutputSize)\n",
    "        self.fc6 = nn.Linear(fc6InputSize, fc6OutputSize)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass X and return probabilities of source and domain.\"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.maxPool2D1(x))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.maxPool2D2(x))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.maxPool2D3(x))\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fcOUT(x))\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation - Geometric Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising\n",
    "\n",
    "# Geometric transformations\n",
    "# Zero-masked noise\n",
    "# Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
